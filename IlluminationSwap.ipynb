{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model based on \"Single Image Portrait Relighting\" whose aim is to produce same scenes as given with illumination conditions (color/light direction) swapped between 2 given inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoding(nn.Module):\n",
    "    def __init__(self, in_channels=3, enc_channels=32):\n",
    "        super(ImageEncoding, self).__init__()\n",
    "        self.convolve = nn.Conv2d(in_channels, enc_channels - in_channels, 7, padding=1)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        conv_out = convolve(img)\n",
    "        return torch.cat((conv_out, img), dim=1)  # append image channels to the convolution result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownDoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, channels_per_group=16):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 3, padding=1),\n",
    "            nn.GroupNorm(in_channels // channels_per_group, in_channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, stride=2, padding=1),\n",
    "            nn.GroupNorm(out_channels // channels_per_group, out_channels),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBottleneckConv(nn.Module):\n",
    "    def __init__(self, in_channels, channels_per_group=16, envmap_H=16, envmap_W=32, depth=4):\n",
    "        expected_channels = envmap_H * envmap_W\n",
    "        assert in_channels == expected_channels, f'DownBottleneck input has {in_channels} channels, expected {expected_channels}'\n",
    "        super(DownBottleneckConv, self).__init__()\n",
    "        self.convolutions = self._build_bottleneck_convolutions(in_channels, channels_per_group, depth)\n",
    "    \n",
    "    def _build_bottleneck_convolutions(self, in_channels, channels_per_group, depth):\n",
    "        single_conv = [\n",
    "            nn.Conv2d(in_channels, in_channels, 3, padding=1),\n",
    "            nn.GroupNorm(in_channels // channels_per_group, in_channels),\n",
    "            nn.PReLU()\n",
    "        ]\n",
    "        convolutions = single_conv * (depth - 1)\n",
    "        \n",
    "        # final layer before weighted pooling\n",
    "        out_channels = 4*in_channels\n",
    "        convolutions += [\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.GroupNorm(out_channels // channels_per_group, out_channels),\n",
    "            nn.Softplus()\n",
    "        ]\n",
    "        \n",
    "        return nn.ModuleList(convolutions)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for module in self.convolutions:\n",
    "            x = module(x)\n",
    "            \n",
    "        # split x into environment map predictions and confidence\n",
    "        channels = x.size()[1]\n",
    "        split_point = 3 * (channels // 4)\n",
    "        envmap_predictions, confidence = x[:, :split_point], x[:, split_point:]\n",
    "        \n",
    "        return envmap_predictions, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WeightedPooling, self).__init__()\n",
    "    \n",
    "    def forward(self, x, weights):\n",
    "        # TODO: multiplication with sum can be probably implemented as convolution with groups (according to some posts)\n",
    "        return (x * weights.repeat((1, 3, 1, 1))).sum(dim=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tiling(nn.Module):\n",
    "    def __init__(self, size=16, in_channels=1536, out_channels=512, channels_per_group=16):\n",
    "        super(Tiling, self).__init__()\n",
    "        self.size = size\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.GroupNorm(out_channels // channels_per_group, out_channels),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        tiled = x.repeat((1, 1, self.size, self.size))\n",
    "        return encode(tiled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Articles on transposed convolutions:\n",
    "* [Convolution types](https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d)\n",
    "* [Upsampling with transposed convolution](https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_concat(x, y):\n",
    "    return torch.cat((x, y), dim=1)\n",
    "\n",
    "class UpBottleneckConv(nn.Module):\n",
    "    def __init__(self, in_channels, channels_per_group=16, envmap_H=16, envmap_W=32, depth=4):\n",
    "        expected_channels = envmap_H * envmap_W\n",
    "        assert depth >= 2, f'Depth should be not smaller than 3'\n",
    "        assert in_channels == expected_channels, f'UpBottleneck input has {in_channels} channels, expected {expected_channels}'\n",
    "        super(UpBottleneckConv, self).__init__()\n",
    "        self.depth = depth\n",
    "        \n",
    "        half_in_channels = in_channels // 2\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, half_in_channels, 3)\n",
    "            nn.GroupNorm(half_in_channels // channels_per_group, half_in_channels),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        self.initial_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels + half_in_channels, in_channels, 3),\n",
    "            nn.GroupNorm(in_channels // channels_per_group, in_channels),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.ConvTranspose2d(2*in_channels, in_channels, 3),\n",
    "            nn.GroupNorm(in_channels // channels_per_group, in_channels),\n",
    "            nn.PReLU()\n",
    "        ] * (depth - 3))\n",
    "        self.out_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2*in_channels, half_in_channels, 3, stride=2),\n",
    "            nn.GroupNorm(half_in_channels // channels_per_group, half_in_channels),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, skip_connections):\n",
    "        assert isinstance(skip_connections, list), 'skip_connections should be a list of corresponding encoder activations'\n",
    "        expected_skip_connections = self.depth - 1\n",
    "        assert len(skip_connections) == expected_skip_connections, f'skip_connections should contain {expected_skip_connections} activations'\n",
    "        \n",
    "        # encoding convolution\n",
    "        x = self.encode(x)\n",
    "        \n",
    "        # transposed convolutions with skip connections\n",
    "        x = self.initial_conv(channel_concat(x, skip_connections.pop()))\n",
    "        for conv in self.convs:\n",
    "            x = conv(channel_concat(x, skip_connections.pop()))\n",
    "        return self.out_conv(channel_concat(x, skip_connections.pop()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpDoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, channels_per_group=16):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2*in_channels, in_channels, 3),\n",
    "            nn.GroupNorm(in_channels // channels_per_group, in_channels),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2*in_channels, out_channels, stride=2),\n",
    "            nn.GroupNorm(out_channels // channels_per_group, out_channels),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, skip_connections):\n",
    "        assert isinstance(skip_connections, list)\n",
    "        assert len(skip_connections) == 2\n",
    "        x = self.conv1(channel_concat(x, skip_connections.pop()))\n",
    "        return self.conv2(channel_concat(x, skip_connections.pop()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Output(nn.Module):\n",
    "    def __init__(self, in_channels=64, out_channels=3):\n",
    "        super(Ouput, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, 3),  # should it be conv or transposed conv?\n",
    "            nn.GroupNorm(1, out_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, encoded_img):\n",
    "        return self.block(channel_concat(x, encoded_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IlluminationSwapNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IlluminationSwapNet, self).__init__()\n",
    "        self.image_encoder = ImageEncoding()\n",
    "        \n",
    "        # down\n",
    "        self.layer128 = DownDoubleConv(64, 128)\n",
    "        self.layer64 = DownDoubleConv(128, 256)\n",
    "        self.layer32 = DownDoubleConv(256, 512)\n",
    "        self.down_bottleneck = DownBottleneckConv(512)\n",
    "        self.weighted_pool = WeightedPooling()\n",
    "        \n",
    "        # up\n",
    "        self.tiling = Tiling()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
